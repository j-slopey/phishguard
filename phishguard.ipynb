{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319bcc8e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079b93e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slopey/Documents/phishguard/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nigerian_Fraud.csv\n",
      "Ling.csv\n",
      "Nazario.csv\n",
      "SpamAssasin.csv\n",
      "CEAS_08.csv\n"
     ]
    }
   ],
   "source": [
    "import os, time, json\n",
    "import kagglehub\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "path = kagglehub.dataset_download(\"naserabdullahalam/phishing-email-dataset\")\n",
    "data = []\n",
    "\n",
    "datasets = [\n",
    "    \"Nigerian_Fraud.csv\",\n",
    "    \"Ling.csv\",\n",
    "    \"Nazario.csv\",\n",
    "    \"SpamAssasin.csv\",\n",
    "    \"CEAS_08.csv\",\n",
    "    # \"Enron.csv\"\n",
    " ]\n",
    "for file in datasets:\n",
    "    print(file)\n",
    "    csv_path = os.path.join(path, file)\n",
    "    subset_data = pd.read_csv(csv_path)\n",
    "    data.append(subset_data)\n",
    "\n",
    "all_data = pd.concat(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f54594",
   "metadata": {},
   "source": [
    "## Clean & Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daf6a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['receiver'] = all_data['receiver'].str.replace('undisclosed-recipients:;', 'Unknown')\n",
    "# -- Timestamp features -- \n",
    "all_data['date_parsed'] = pd.to_datetime(all_data['date'], errors='coerce', utc=True)\n",
    "\n",
    "# Week-of-year\n",
    "iso_week = all_data['date_parsed'].dt.isocalendar().week\n",
    "iso_week = iso_week.astype(float)\n",
    "week0 = ((iso_week - 1) % 52)\n",
    "theta_week = 2.0 * np.pi * week0 / 52\n",
    "all_data['sin_week'] = np.where(week0.notna(), np.sin(theta_week), 0.0)\n",
    "all_data['cos_week'] = np.where(week0.notna(), np.cos(theta_week), 0.0)\n",
    "\n",
    "# Hour-of-day \n",
    "hour = all_data['date_parsed'].dt.hour.astype(float)  # NaN for missing\n",
    "theta_hour = 2.0 * np.pi * hour / 24\n",
    "all_data['sin_hour'] = np.where(hour.notna(), np.sin(theta_hour), 0.0)\n",
    "all_data['cos_hour'] = np.where(hour.notna(), np.cos(theta_hour), 0.0)\n",
    "\n",
    "# Weekend binary (0/1)\n",
    "weekday = all_data['date_parsed'].dt.weekday\n",
    "all_data['is_weekend'] = np.where(weekday.isna(), 0, ((weekday >= 5).astype(int)))\n",
    "\n",
    "# Timestamp feature list\n",
    "timestamp_features = [\n",
    "    \"sin_week\",\n",
    "    \"cos_week\",\n",
    "    \"sin_hour\",\n",
    "    \"cos_hour\",\n",
    "    \"is_weekend\"\n",
    "]\n",
    "\n",
    "# -- Sender/reciever feature engineering -- \n",
    "with open('domains.json', 'r') as file:\n",
    "    public_email_domains = json.load(file)\n",
    "    \n",
    "email_regex = r'([a-zA-Z0-9._%+\\-|{}^&\"\\'=]+@(?:[a-zA-Z0-9.-]+|\\[[0-9.]+\\]))'    \n",
    "for column_name in ('sender', 'receiver'):\n",
    "    all_data[f'{column_name}_email'] = all_data[column_name].str.extract(email_regex, expand=False)\n",
    "    all_data[f'{column_name}_domain'] = all_data[f'{column_name}_email'].str.split('@', n=1).str[1]\n",
    "    all_data[f'{column_name}_domain_len'] = all_data[f'{column_name}_domain'].str.len()\n",
    "    all_data[f'{column_name}_domain_public'] = all_data[f'{column_name}_domain'].str.lower().isin(public_email_domains).astype(int)\n",
    "    all_data[f'{column_name}_n_subdomains'] = all_data[f'{column_name}_domain'].str.lower().str.count(r'\\.')\n",
    "    all_data[f'{column_name}_email_n_digits'] = all_data[f'{column_name}_domain'].str.lower().str.count(r'\\d')\n",
    "    \n",
    "    all_data[f'{column_name}_name'] = all_data[column_name].str.replace(email_regex, '', regex=True)\n",
    "    all_data[f'{column_name}_name'] = all_data[f'{column_name}_name'].str.replace(r'[<>\"\\'\\(\\)]', '', regex=True).str.strip()\n",
    "    \n",
    "all_data['is_internal_email'] = (\n",
    "    (all_data['sender_domain'] == all_data['receiver_domain']) & \n",
    "    (all_data['sender_domain'].notna())\n",
    ").astype(int)\n",
    "\n",
    "all_data['sender_name_contains_email'] = all_data['sender_name'].str.contains('@', na=False).astype(int)\n",
    "\n",
    "# Sender/reciever feature list\n",
    "email_features = [\n",
    "    \"sender_domain_public\",\n",
    "    \"sender_domain_len\",\n",
    "    \"sender_n_subdomains\",\n",
    "    \"sender_email_n_digits\",\n",
    "    \"sender_name_contains_email\",\n",
    "    # \"is_internal_email\"\n",
    "]\n",
    "\n",
    "# -- Fill in url count for missing entries -- \n",
    "url_regex = r'((?:https?|ftp)://\\S+|www\\.\\S+)'\n",
    "text_column = 'body' \n",
    "missing_count_mask = all_data['urls'].isna()\n",
    "all_data.loc[missing_count_mask, 'urls'] = (\n",
    "    all_data.loc[missing_count_mask, text_column]\n",
    "    .astype(str)\n",
    "    .str.count(url_regex)\n",
    ")\n",
    "\n",
    "all_data[['body', 'subject']] = all_data[['body', 'subject']].fillna('Unknown')\n",
    "\n",
    "feature_set= [\n",
    "    'subject',\n",
    "    'body',\n",
    "    *email_features,\n",
    "    *timestamp_features\n",
    "]\n",
    "\n",
    "X = all_data[feature_set]\n",
    "y = all_data['label'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66bc3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Initialize Model --\n",
    "vectorizer = ColumnTransformer([\n",
    "    ('subject_word', TfidfVectorizer(lowercase=False, analyzer='word'), 'subject'),\n",
    "    ('subject_charwb', TfidfVectorizer(lowercase=False, analyzer='char_wb'), 'subject'),\n",
    "    ('body', TfidfVectorizer(lowercase=True, analyzer='word'), 'body' )\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('xgboost', XGBClassifier())\n",
    "        \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c672d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-10 15:09:21,751] A new study created in memory with name: no-name-e90d41d8-aee1-4690-9ad7-17e608fa8402\n",
      "/home/slopey/Documents/phishguard/.venv/lib/python3.12/site-packages/xgboost/core.py:774: UserWarning: [15:09:37] WARNING: /workspace/src/common/error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-12-10 15:09:37,729] Trial 0 finished with value: 0.9886252843678908 and parameters: {'n_estimators': 409, 'learning_rate': 0.2561516577796873, 'max_depth': 6, 'subsample': 0.2486585499849276, 'colsample_bytree': 0.5794417199890765, 'ngram_range': 'unigram', 'stop_words_setting': 'english', 'df_min_type': 'float', 'min_df': 0.00010252767065199794, 'max_features': 127830}. Best is trial 0 with value: 0.9886252843678908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 done in 15.97s | F1: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-10 15:09:59,531] Trial 1 finished with value: 0.9859732412602503 and parameters: {'n_estimators': 627, 'learning_rate': 0.012213351095064886, 'max_depth': 7, 'subsample': 0.5982042287251315, 'colsample_bytree': 0.6045844671523367, 'ngram_range': 'unigram', 'stop_words_setting': 'english', 'df_min_type': 'float', 'min_df': 0.009201110047530457, 'max_features': 260107}. Best is trial 0 with value: 0.9886252843678908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 done in 21.80s | F1: 0.9860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-10 15:10:22,020] Trial 2 finished with value: 0.9725968743309784 and parameters: {'n_estimators': 241, 'learning_rate': 0.02153907863344698, 'max_depth': 5, 'subsample': 0.182227862202037, 'colsample_bytree': 0.6176206980243029, 'ngram_range': 'bigram', 'stop_words_setting': 'english', 'df_min_type': 'int', 'df_min': 15}. Best is trial 0 with value: 0.9886252843678908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 done in 22.47s | F1: 0.9726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-12-10 15:12:13,141] Trial 3 failed with parameters: {'n_estimators': 881, 'learning_rate': 0.013613401332156829, 'max_depth': 12, 'subsample': 0.7616186899856062, 'colsample_bytree': 0.7910825895672595, 'ngram_range': 'bigram', 'stop_words_setting': 'english', 'df_min_type': 'float', 'min_df': 0.22402050793949568} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/slopey/Documents/phishguard/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_5800/2859205347.py\", line 77, in objective\n",
      "    model.fit(\n",
      "  File \"/home/slopey/Documents/phishguard/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/slopey/Documents/phishguard/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/slopey/Documents/phishguard/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/slopey/Documents/phishguard/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/slopey/Documents/phishguard/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2434, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-12-10 15:12:13,142] Trial 3 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 95\u001b[39m\n\u001b[32m     92\u001b[39m start = time.perf_counter()\n\u001b[32m     93\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m, pruner=optuna.pruners.MedianPruner(n_startup_trials=\u001b[32m20\u001b[39m, n_warmup_steps=\u001b[32m20\u001b[39m, interval_steps=\u001b[32m100\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m end = time.perf_counter()\n\u001b[32m     98\u001b[39m duration = end - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/phishguard/.venv/lib/python3.12/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/phishguard/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/phishguard/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/phishguard/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/phishguard/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     59\u001b[39m pruning_callback = XGBoostPruningCallback(trial, \u001b[33m\"\u001b[39m\u001b[33mvalidation_0-auc\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m model = XGBClassifier(\n\u001b[32m     62\u001b[39m     n_estimators=n_estimators,\n\u001b[32m     63\u001b[39m     learning_rate=learning_rate,\n\u001b[32m   (...)\u001b[39m\u001b[32m     74\u001b[39m     callbacks=[pruning_callback]\n\u001b[32m     75\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_sub_train_vec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_sub_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sub_valid_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sub_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     82\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# --- 5. Evaluate ---\u001b[39;00m\n\u001b[32m     85\u001b[39m preds = model.predict(X_sub_valid_vec)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/phishguard/.venv/lib/python3.12/site-packages/xgboost/core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/phishguard/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1806\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1786\u001b[39m evals_result: EvalsLog = {}\n\u001b[32m   1787\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1788\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1789\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1803\u001b[39m     feature_types=feature_types,\n\u001b[32m   1804\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1806\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1807\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1808\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1809\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1810\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1811\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1812\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1813\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1814\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1815\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1816\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1817\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1818\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1820\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1821\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/phishguard/.venv/lib/python3.12/site-packages/xgboost/core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/phishguard/.venv/lib/python3.12/site-packages/xgboost/training.py:199\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/phishguard/.venv/lib/python3.12/site-packages/xgboost/core.py:2434\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2430\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2433\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2434\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2435\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2436\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2437\u001b[39m     )\n\u001b[32m   2438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2439\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# -- Hyperparameter tuning with Optuna -- \n",
    "GPU = True\n",
    "def objective(trial):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Define Search Space\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 12)\n",
    "    subsample = trial.suggest_float('subsample', 0.15, .9)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "    \n",
    "    ngram_choice = trial.suggest_categorical('ngram_range', ['unigram', 'bigram'])\n",
    "    ngram_range = (1, 1) if ngram_choice == 'unigram' else (1, 2)\n",
    "    stop_words_choice = trial.suggest_categorical('stop_words_setting', ['english', 'none'])\n",
    "    stop_words = 'english' if stop_words_choice == 'english' else None\n",
    "    df_min_type = trial.suggest_categorical('df_min_type', ['int', 'float'])\n",
    "\n",
    "\n",
    "    max_features = None\n",
    "    if df_min_type == 'int':\n",
    "        min_df = trial.suggest_int('df_min', 2, 20)\n",
    "    elif df_min_type == 'float':\n",
    "        min_df = trial.suggest_float('min_df', 0.0001, 0.3, log=True)\n",
    "        max_features = trial.suggest_int('max_features', 10000, 300000) if min_df < 0.01 else None\n",
    "\n",
    "    \n",
    "    # Build Vectorizer\n",
    "    vectorizer = ColumnTransformer([\n",
    "        ('subject_word_vectorizer', TfidfVectorizer(lowercase=False, analyzer='word', ngram_range=ngram_range), 'subject'),\n",
    "        ('subject_charwb_vectorizer', TfidfVectorizer(lowercase=False, analyzer='char_wb'), 'subject'),\n",
    "        ('body_vectorizer', TfidfVectorizer(\n",
    "            lowercase=True, \n",
    "            analyzer='word', \n",
    "            min_df=min_df, \n",
    "            ngram_range=ngram_range,\n",
    "            stop_words=stop_words,\n",
    "            max_features=max_features\n",
    "        ), 'body')\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "    \n",
    "    # Train/Validation Split\n",
    "    X_sub_train, X_sub_valid, y_sub_train, y_sub_valid = train_test_split(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42 + trial.number,\n",
    "        stratify=y_train\n",
    "    )\n",
    "    vectorizer.fit(X_sub_train)\n",
    "    X_sub_train_vec = vectorizer.transform(X_sub_train)\n",
    "    X_sub_valid_vec = vectorizer.transform(X_sub_valid)\n",
    "    \n",
    "    # Model with pruning + early stopping\n",
    "    pruning_callback = XGBoostPruningCallback(trial, \"validation_0-auc\")\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        n_jobs=-1,\n",
    "        tree_method='hist',\n",
    "        device='cuda' if GPU else 'cpu',\n",
    "        random_state=42,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=30,\n",
    "        callbacks=[pruning_callback]\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_sub_train_vec,\n",
    "        y_sub_train,\n",
    "        eval_set=[(X_sub_valid_vec, y_sub_valid)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    preds = model.predict(X_sub_valid_vec)\n",
    "    f1 = f1_score(y_sub_valid, preds)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Trial {trial.number} done in {elapsed:.2f}s | F1: {f1:.4f}\")\n",
    "    return f1\n",
    "    \n",
    "start = time.perf_counter()\n",
    "study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(n_startup_trials=20, n_warmup_steps=20, interval_steps=100))\n",
    "\n",
    "study.optimize(objective, n_trials=100, n_jobs=1)\n",
    "\n",
    "end = time.perf_counter()\n",
    "duration = end - start\n",
    "print(f\"Study took: {duration//(60**2)}m {duration//60}m {round(duration%60)}s\")\n",
    "print(f\"Best value: {study.best_value}\")\n",
    "print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0225d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b5265b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
